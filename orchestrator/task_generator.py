import sys
import time
import json
import redis
import random
from utilities import get_config, init_redis_client, clear_queues, generate_matrix


def generate_and_push_tasks(num_tasks_to_generate, redis_client, input_queue):
    """
    Generates a specified number of structured tasks (matrix multiplication),
    and pushes them to the Redis input queue.
    """
    print(f"Starting to generate {num_tasks_to_generate} tasks and pushing to '{input_queue}'...")
    
    for i in range(num_tasks_to_generate):
        # Determine matrix size for this task (e.g., between 10x10 and 100x100)
        task_data_size = random.randint(10, 100) 
        
        # Generate the two matrices for multiplication
        matrix_A = generate_matrix(task_data_size)
        matrix_B = generate_matrix(task_data_size)
        
        # --- Construct the refined task dictionary ---
        task_payload = {
            "task_application": "matrix_multiplication",
            "task_data": [matrix_A, matrix_B], # The actual matrices
            # "task_data": None,  # Placeholder for matrices, to be generated by workers
            "task_data_size": task_data_size,  # The dimension of the matrices
            "task_deadline": None,             # Placeholder for task deadline
        }

        # Convert to JSON and get size before pushing
        current_time = time.strftime("%Y-%m-%d %H:%M:%S")        
        task_json = json.dumps(task_payload)
        json_size = len(task_json.encode('utf-8'))  # Size in bytes

        try:
            # Push the JSON string of the task payload to the Redis list
            redis_client.lpush(input_queue, task_json)

            # Log detailed information about the pushed task
            print(f"[{current_time}] Pushed task {i+1}/{num_tasks_to_generate}: "
                  f"size={json_size} bytes, matrix={task_data_size}x{task_data_size}")

            if (i + 1) % 100 == 0 or (i + 1) == num_tasks_to_generate:
                time.sleep(1)  # Sleep to avoid overwhelming Redis with too many requests at once
                print(f"  Batch update: Pushed {i + 1}/{num_tasks_to_generate} tasks. Last task data size: {task_data_size}x{task_data_size}")
        except redis.exceptions.ConnectionError as e:
            print(f"[{current_time}] Redis lpush connection error: {str(e)}. Attempting to reinitialize.")
            time.sleep(5)
            try:
                redis_client = init_redis_client() # Reinitialize blocking client
                redis_client.lpush(input_queue, task_json)
                print(f"[{current_time}] Recovered: Pushed task {i+1} after reconnection")
            except Exception as init_e:
                print(f"[{current_time}] CRITICAL ERROR: Redis reinit and lpush failed: {init_e}", file=sys.stderr)
                return {"statusCode": 500, "body": f"Redis failure: {init_e}"}
        except Exception as e:
            print(f"[{current_time}] ERROR: Failed to push task {i+1}: {e}", file=sys.stderr)
            return

    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Successfully finished generating and pushing {num_tasks_to_generate} tasks to '{input_queue}'.")


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python task_generator.py <number_of_tasks_to_generate>")
        sys.exit(1)

    try:
        num_tasks = int(sys.argv[1])
        if num_tasks <= 0:
            raise ValueError("Number of tasks to generate must be a positive integer.")
    except ValueError as e:
        print(f"Invalid argument for number of tasks: {e}", file=sys.stderr)
        sys.exit(1)

    config = get_config()

    try:
        redis_client = init_redis_client()
    except redis.exceptions.ConnectionError as e:
        print(f"Redis connection error: {str(e)}. Attempting to reinitialize.")
        time.sleep(5)
        try:
            redis_client = init_redis_client() # Reinitialize blocking client
        except Exception as init_e:
            print(f"CRITICAL ERROR: Redis reinit failed: {init_e}", file=sys.stderr)
            raise
    clear_queues(redis_client, None)  # Clear all queues before generating tasks
    generate_and_push_tasks(num_tasks, redis_client, config['input_queue_name'])
